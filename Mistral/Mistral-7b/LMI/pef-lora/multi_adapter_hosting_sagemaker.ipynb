{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844f22ae-6b01-4a17-820b-83f9d34de23e",
   "metadata": {},
   "source": [
    "# Serve multiple LoRA adapters efficiently on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cd38c-ad40-4a3e-b225-4d1f707a0c0e",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to serve many Low-Rank Adapters (LoRA) on top of the same base model efficiently on the same GPU. In order to do this, we'll deploy the LoRA Exchange ([LoRAX](https://github.com/predibase/lorax/tree/main)) inference server to SageMaker Hosting. \n",
    "\n",
    "These are the steps we will take:\n",
    "\n",
    "1. [Setup our environment](#setup)\n",
    "2. [Build a new LoRAX container image compatible with SageMaker, push it to Amazon ECR](#container)\n",
    "3. [Download adapters from the HuggingFace Hub and upload them to S3](#download_adapter)\n",
    "4. [Deploy the extended LoRAX container to SageMaker](#deploy)\n",
    "5. [Compare outputs of the base model and the adapter model](#compare)\n",
    "6. [Benchmark our deployed endpoint under different traffic patterns - same adapter, and random access to many adapters](#benchmark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65e8be-3073-4436-b311-11a3de09e101",
   "metadata": {},
   "source": [
    "## What is LoRAX? \n",
    "\n",
    "LoRAX is a production-ready framework specialized in multi-adapter serving that  efficiently share the same GPU resources, which dramatically reduces the cost of serving without compromising on throughput or latency. Some of the features that enable this are: \n",
    "\n",
    "* Dynamic Adapter Loading - fine-tuned LoRA weights are loaded from storage (local or remote) just-in-time as requests come in at runtime\n",
    "* Tiered Weight Caching - fast exchanging of LoRA adapters between requests, and offloading of adapter weights to CPU and disk as they are not needed to avoid out-of-memory errors.\n",
    "* Continuous Multi-Adapter Batching - a fair scheduling policy that continuously batches requests targeted at different LoRA adapters so they can be processed in paralle, optimizing aggregate throughput.\n",
    "* Optimized Inference - high throughput and low latency optimizations including tensor parallelism, pre-compiled CUDA kernels ([flash-attention](https://arxiv.org/abs/2307.08691), [paged attention](https://arxiv.org/abs/2309.06180), [SGMV](https://arxiv.org/abs/2310.18547)), quantization, token streaming.\n",
    "\n",
    "You can read more about LoRAX [here](https://predibase.com/blog/lora-exchange-lorax-serve-100s-of-fine-tuned-llms-for-the-cost-of-one).\n",
    "\n",
    "#### Can we teach a new language to the Large Model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4372522-fb5d-4cad-be37-d4f21f794698",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup our environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf3acc-e2fc-48ca-a21e-4377c7638d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U boto3 sagemaker huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d8394b-5d69-4c02-97fe-d00eccc4da26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::622343165275:role/SagemakerEMRNoAuthProductWi-SageMakerExecutionRole-405QXR1USJDE\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "region = sess._region_name \n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d6fd3-5d59-4bc2-8cf2-ad4c32d072b7",
   "metadata": {},
   "source": [
    "<a id=\"container\"></a>\n",
    "## 2. Build a new LoRAX container image compatible with SageMaker, push it to Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9d085-897f-46a4-875f-798f0ebb1f61",
   "metadata": {},
   "source": [
    "This example includes a `Dockerfile` and `sagemaker_entrypoint.sh` in the `sagemaker_lorax` directory. Building this new container image makes LoRAX compatible with SageMaker Hosting, namely launching the server on port 8080 via the container's `ENTRYPOINT` instruction. [Here](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-code-run-image) you can find the basic interfaces required to adapt any container for deployment on Sagemaker Hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0eafe8-2398-43e0-9dd6-e211c23ba5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "if [[ -z \"${HF_MODEL_ID}\" ]]; then\n",
      "  echo \"HF_MODEL_ID must be set\"\n",
      "  exit 1\n",
      "fi\n",
      "export MODEL_ID=\"${HF_MODEL_ID}\"\n",
      "\n",
      "if [[ -n \"${HF_MODEL_REVISION}\" ]]; then\n",
      "  export REVISION=\"${HF_MODEL_REVISION}\"\n",
      "fi\n",
      "\n",
      "if [[ -n \"${SM_NUM_GPUS}\" ]]; then\n",
      "  export NUM_SHARD=\"${SM_NUM_GPUS}\"\n",
      "fi\n",
      "\n",
      "if [[ -n \"${HF_MODEL_QUANTIZE}\" ]]; then\n",
      "  export QUANTIZE=\"${HF_MODEL_QUANTIZE}\"\n",
      "fi\n",
      "\n",
      "if [[ -n \"${HF_MODEL_TRUST_REMOTE_CODE}\" ]]; then\n",
      "  export TRUST_REMOTE_CODE=\"${HF_MODEL_TRUST_REMOTE_CODE}\"\n",
      "fi\n",
      "\n",
      "if [[ -z \"${ADAPTER_BUCKET}\" ]]; then\n",
      "  echo \"Warning: ADAPTER_BUCKET not set. Only able to load local or HuggingFace Hub models.\"\n",
      "else\n",
      "  export PREDIBASE_MODEL_BUCKET=\"${ADAPTER_BUCKET}\"\n",
      "fi\n",
      "\n",
      "lorax-launcher --port 8080\n"
     ]
    }
   ],
   "source": [
    "!cat sagemaker_lorax/sagemaker_entrypoint.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2cc01a-13e6-4d6e-9637-00dc2e94050d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM ghcr.io/predibase/lorax:0.7.0\n",
      "\n",
      "RUN apt-get install wget\n",
      "RUN wget \\\n",
      "    https://raw.githubusercontent.com/predibase/lorax/v0.8.1/server/lorax_server/utils/sources/__init__.py \\\n",
      "    https://raw.githubusercontent.com/predibase/lorax/v0.8.1/server/lorax_server/utils/sources/s3.py \\\n",
      "    && mv -t /usr/src/server/lorax_server/utils/sources/ __init__.py s3.py\n",
      "\n",
      "COPY sagemaker_entrypoint.sh entrypoint.sh\n",
      "RUN chmod +x entrypoint.sh\n",
      "\n",
      "ENTRYPOINT [\"./entrypoint.sh\"]\n"
     ]
    }
   ],
   "source": [
    "!cat sagemaker_lorax/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0c937-9e17-42ea-afc5-31d5dbff6331",
   "metadata": {},
   "source": [
    "We build the new container image and push it to a new ECR repository. Note SageMaker [supports private Docker registries](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-containers-inference-private.html) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02779726-b57f-472b-9d09-6a1aabc56a10",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.584kB\n",
      "Step 1/6 : FROM ghcr.io/predibase/lorax:0.7.0\n",
      "0.7.0: Pulling from predibase/lorax\n",
      "96d54c3075c9: Pulling fs layer\n",
      "09d415c238d7: Pulling fs layer\n",
      "9fe6e2e61518: Pulling fs layer\n",
      "41f16248e682: Pulling fs layer\n",
      "95d7b7817039: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "959f82742943: Pulling fs layer\n",
      "9025bd344ce7: Pulling fs layer\n",
      "adfa41a6373b: Pulling fs layer\n",
      "c4446226bc69: Pulling fs layer\n",
      "e8967d84bc78: Pulling fs layer\n",
      "058d42d7b817: Pulling fs layer\n",
      "c229ba7b2d98: Pulling fs layer\n",
      "8e1085530a30: Pulling fs layer\n",
      "4e3516d65361: Pulling fs layer\n",
      "36fbc80e3462: Pulling fs layer\n",
      "734c9cff5cc4: Pulling fs layer\n",
      "520ce0040a14: Pulling fs layer\n",
      "c01e26680578: Pulling fs layer\n",
      "c7df9566c432: Pulling fs layer\n",
      "899130d4026e: Pulling fs layer\n",
      "15bb6f25c9d7: Pulling fs layer\n",
      "80097af03388: Pulling fs layer\n",
      "b6e1027e7d59: Pulling fs layer\n",
      "f4a90201c6e3: Pulling fs layer\n",
      "a77df8ee08a0: Pulling fs layer\n",
      "324dcf76c071: Pulling fs layer\n",
      "604daeae5aff: Pulling fs layer\n",
      "59412145b155: Pulling fs layer\n",
      "7b8cf8b70529: Pulling fs layer\n",
      "81d280262614: Pulling fs layer\n",
      "a75a1bcd944c: Pulling fs layer\n",
      "8a37496829ba: Pulling fs layer\n",
      "41f16248e682: Waiting\n",
      "95d7b7817039: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "959f82742943: Waiting\n",
      "9025bd344ce7: Waiting\n",
      "adfa41a6373b: Waiting\n",
      "c4446226bc69: Waiting\n",
      "e8967d84bc78: Waiting\n",
      "058d42d7b817: Waiting\n",
      "c229ba7b2d98: Waiting\n",
      "8e1085530a30: Waiting\n",
      "4e3516d65361: Waiting\n",
      "36fbc80e3462: Waiting\n",
      "734c9cff5cc4: Waiting\n",
      "520ce0040a14: Waiting\n",
      "c01e26680578: Waiting\n",
      "c7df9566c432: Waiting\n",
      "899130d4026e: Waiting\n",
      "15bb6f25c9d7: Waiting\n",
      "80097af03388: Waiting\n",
      "b6e1027e7d59: Waiting\n",
      "f4a90201c6e3: Waiting\n",
      "a77df8ee08a0: Waiting\n",
      "324dcf76c071: Waiting\n",
      "604daeae5aff: Waiting\n",
      "59412145b155: Waiting\n",
      "7b8cf8b70529: Waiting\n",
      "81d280262614: Waiting\n",
      "a75a1bcd944c: Waiting\n",
      "8a37496829ba: Waiting\n",
      "09d415c238d7: Verifying Checksum\n",
      "09d415c238d7: Download complete\n",
      "96d54c3075c9: Verifying Checksum\n",
      "96d54c3075c9: Download complete\n",
      "41f16248e682: Verifying Checksum\n",
      "41f16248e682: Download complete\n",
      "95d7b7817039: Verifying Checksum\n",
      "95d7b7817039: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "959f82742943: Verifying Checksum\n",
      "959f82742943: Download complete\n",
      "9fe6e2e61518: Verifying Checksum\n",
      "9fe6e2e61518: Download complete\n",
      "adfa41a6373b: Verifying Checksum\n",
      "adfa41a6373b: Download complete\n",
      "e8967d84bc78: Verifying Checksum\n",
      "e8967d84bc78: Download complete\n",
      "c4446226bc69: Verifying Checksum\n",
      "c4446226bc69: Download complete\n",
      "058d42d7b817: Verifying Checksum\n",
      "058d42d7b817: Download complete\n",
      "c229ba7b2d98: Verifying Checksum\n",
      "c229ba7b2d98: Download complete\n",
      "8e1085530a30: Verifying Checksum\n",
      "8e1085530a30: Download complete\n",
      "4e3516d65361: Verifying Checksum\n",
      "4e3516d65361: Download complete\n",
      "36fbc80e3462: Verifying Checksum\n",
      "36fbc80e3462: Download complete\n",
      "734c9cff5cc4: Verifying Checksum\n",
      "734c9cff5cc4: Download complete\n",
      "520ce0040a14: Verifying Checksum\n",
      "520ce0040a14: Download complete\n",
      "c7df9566c432: Verifying Checksum\n",
      "c7df9566c432: Download complete\n",
      "c01e26680578: Verifying Checksum\n",
      "c01e26680578: Download complete\n",
      "899130d4026e: Verifying Checksum\n",
      "899130d4026e: Download complete\n",
      "80097af03388: Verifying Checksum\n",
      "80097af03388: Download complete\n",
      "b6e1027e7d59: Verifying Checksum\n",
      "b6e1027e7d59: Download complete\n",
      "96d54c3075c9: Pull complete\n",
      "f4a90201c6e3: Verifying Checksum\n",
      "f4a90201c6e3: Download complete\n",
      "a77df8ee08a0: Verifying Checksum\n",
      "a77df8ee08a0: Download complete\n",
      "324dcf76c071: Verifying Checksum\n",
      "324dcf76c071: Download complete\n",
      "15bb6f25c9d7: Verifying Checksum\n",
      "15bb6f25c9d7: Download complete\n",
      "09d415c238d7: Pull complete\n",
      "604daeae5aff: Verifying Checksum\n",
      "604daeae5aff: Download complete\n",
      "59412145b155: Verifying Checksum\n",
      "59412145b155: Download complete\n",
      "7b8cf8b70529: Verifying Checksum\n",
      "7b8cf8b70529: Download complete\n",
      "81d280262614: Verifying Checksum\n",
      "81d280262614: Download complete\n",
      "a75a1bcd944c: Verifying Checksum\n",
      "a75a1bcd944c: Download complete\n",
      "8a37496829ba: Verifying Checksum\n",
      "8a37496829ba: Download complete\n",
      "9fe6e2e61518: Pull complete\n",
      "41f16248e682: Pull complete\n",
      "95d7b7817039: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "959f82742943: Pull complete\n",
      "9025bd344ce7: Verifying Checksum\n",
      "9025bd344ce7: Download complete\n",
      "9025bd344ce7: Pull complete\n",
      "adfa41a6373b: Pull complete\n",
      "c4446226bc69: Pull complete\n",
      "e8967d84bc78: Pull complete\n",
      "058d42d7b817: Pull complete\n",
      "c229ba7b2d98: Pull complete\n",
      "8e1085530a30: Pull complete\n",
      "4e3516d65361: Pull complete\n",
      "36fbc80e3462: Pull complete\n",
      "734c9cff5cc4: Pull complete\n",
      "520ce0040a14: Pull complete\n",
      "c01e26680578: Pull complete\n",
      "c7df9566c432: Pull complete\n",
      "899130d4026e: Pull complete\n",
      "15bb6f25c9d7: Pull complete\n",
      "80097af03388: Pull complete\n",
      "b6e1027e7d59: Pull complete\n",
      "f4a90201c6e3: Pull complete\n",
      "a77df8ee08a0: Pull complete\n",
      "324dcf76c071: Pull complete\n",
      "604daeae5aff: Pull complete\n",
      "59412145b155: Pull complete\n",
      "7b8cf8b70529: Pull complete\n",
      "81d280262614: Pull complete\n",
      "a75a1bcd944c: Pull complete\n",
      "8a37496829ba: Pull complete\n",
      "Digest: sha256:18c81db2f48f6153163b11d2c366c40838369605772ea09edc5a613bf778fb3f\n",
      "Status: Downloaded newer image for ghcr.io/predibase/lorax:0.7.0\n",
      " ---> 122756a8aeab\n",
      "Step 2/6 : RUN apt-get install wget\n",
      " ---> Running in 46fc7742d937\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  wget\n",
      "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
      "Need to get 348 kB of archives.\n",
      "After this operation, 1012 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 wget amd64 1.20.3-1ubuntu2 [348 kB]\n",
      "\u001B[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001B[0mFetched 348 kB in 1s (645 kB/s)\n",
      "Selecting previously unselected package wget.\n",
      "(Reading database ... 10639 files and directories currently installed.)\n",
      "Preparing to unpack .../wget_1.20.3-1ubuntu2_amd64.deb ...\n",
      "Unpacking wget (1.20.3-1ubuntu2) ...\n",
      "Setting up wget (1.20.3-1ubuntu2) ...\n",
      "Removing intermediate container 46fc7742d937\n",
      " ---> ff5043a609db\n",
      "Step 3/6 : RUN wget     https://raw.githubusercontent.com/predibase/lorax/v0.8.1/server/lorax_server/utils/sources/__init__.py     https://raw.githubusercontent.com/predibase/lorax/v0.8.1/server/lorax_server/utils/sources/s3.py     && mv -t /usr/src/server/lorax_server/utils/sources/ __init__.py s3.py\n",
      " ---> Running in cb7455f762c8\n",
      "\u001B[91m--2024-03-18 18:53:26--  https://raw.githubusercontent.com/predibase/lorax/v0.8.1/server/lorax_server/utils/sources/__init__.py\n",
      "\u001B[0m\u001B[91mResolving raw.githubusercontent.com (raw.githubusercontent.com)... \u001B[0m\u001B[91m185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... \u001B[0m\u001B[91mconnected.\n",
      "\u001B[0m\u001B[91mHTTP request sent, awaiting response... \u001B[0m\u001B[91m200 OK\n",
      "Length: 3155 (3.1K) [text/plain]\n",
      "\u001B[0m\u001B[91mSaving to: '__init__.py'\n",
      "\n",
      "     0K ...                                                   100% 38.3M=0s\n",
      "\n",
      "2024-03-18 18:53:26 (38.3 MB/s) - '__init__.py' saved [3155/3155]\n",
      "\n",
      "--2024-03-18 18:53:26--  https://raw.githubusercontent.com/predibase/lorax/v0.8.1/server/lorax_server/utils/sources/s3.py\n",
      "Reusing existing connection to raw.githubusercontent.com:443.\n",
      "HTTP request sent, awaiting response... \u001B[0m\u001B[91m200 OK\n",
      "Length: 8761 (8.6K) [text/plain]\n",
      "\u001B[0m\u001B[91mSaving to: 's3.py'\n",
      "\n",
      "     0K ........                                              100% 57.8M=0s\n",
      "\n",
      "2024-03-18 18:53:26 (57.8 MB/s) - 's3.py' saved [8761/8761]\n",
      "\n",
      "\u001B[0m\u001B[91mFINISHED --2024-03-18 18:53:26--\n",
      "Total wall clock time: 0.3s\n",
      "Downloaded: 2 files, 12K in 0s (51.0 MB/s)\n",
      "\u001B[0mRemoving intermediate container cb7455f762c8\n",
      " ---> 477fa4ddf725\n",
      "Step 4/6 : COPY sagemaker_entrypoint.sh entrypoint.sh\n",
      " ---> 6443945edcad\n",
      "Step 5/6 : RUN chmod +x entrypoint.sh\n",
      " ---> Running in 354616bb754f\n",
      "Removing intermediate container 354616bb754f\n",
      " ---> e08d6bf4643e\n",
      "Step 6/6 : ENTRYPOINT [\"./entrypoint.sh\"]\n",
      " ---> Running in 74720b458be7\n",
      "Removing intermediate container 74720b458be7\n",
      " ---> 56419d505c92\n",
      "Successfully built 56419d505c92\n",
      "Successfully tagged sm-lorax:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [622343165275.dkr.ecr.us-east-1.amazonaws.com/sm-lorax]\n",
      "e59fb7ef57a0: Preparing\n",
      "88156e44280f: Preparing\n",
      "6f0bc75cafcf: Preparing\n",
      "587d555f2c9d: Preparing\n",
      "21b57c16a62f: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "5cb39f79cd22: Preparing\n",
      "181eb05384b2: Preparing\n",
      "3657817dc3f0: Preparing\n",
      "f14d86fa3017: Preparing\n",
      "400ac87f472d: Preparing\n",
      "d619dfa00c73: Preparing\n",
      "8c8243578a2b: Preparing\n",
      "261c3774c596: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "3323ffa36a6b: Preparing\n",
      "65411ef2fe39: Preparing\n",
      "96f5d88e1c6e: Preparing\n",
      "8421b2fc221a: Preparing\n",
      "6db0e47080dc: Preparing\n",
      "1dbfef547c88: Preparing\n",
      "4dd4b78d72b9: Preparing\n",
      "01e7f8ae12e2: Preparing\n",
      "0c2888617ca7: Preparing\n",
      "12748023f7f7: Preparing\n",
      "405aa7f9a1db: Preparing\n",
      "30b51295ff33: Preparing\n",
      "da5e3a75a750: Preparing\n",
      "1538db58ab64: Preparing\n",
      "fb1883f1cf7b: Preparing\n",
      "c8a655e8e8cd: Preparing\n",
      "83d1bc0501bc: Preparing\n",
      "e35acfadf1d1: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "f344b08ff6c5: Preparing\n",
      "86f0cc586e78: Preparing\n",
      "33e57ea5b30a: Preparing\n",
      "851dfeb18192: Preparing\n",
      "6c3e7df31590: Preparing\n",
      "5f70bf18a086: Waiting\n",
      "5cb39f79cd22: Waiting\n",
      "181eb05384b2: Waiting\n",
      "3657817dc3f0: Waiting\n",
      "f14d86fa3017: Waiting\n",
      "400ac87f472d: Waiting\n",
      "d619dfa00c73: Waiting\n",
      "8c8243578a2b: Waiting\n",
      "261c3774c596: Waiting\n",
      "3323ffa36a6b: Waiting\n",
      "65411ef2fe39: Waiting\n",
      "96f5d88e1c6e: Waiting\n",
      "8421b2fc221a: Waiting\n",
      "6db0e47080dc: Waiting\n",
      "c8a655e8e8cd: Waiting\n",
      "1dbfef547c88: Waiting\n",
      "4dd4b78d72b9: Waiting\n",
      "01e7f8ae12e2: Waiting\n",
      "0c2888617ca7: Waiting\n",
      "83d1bc0501bc: Waiting\n",
      "12748023f7f7: Waiting\n",
      "e35acfadf1d1: Waiting\n",
      "f344b08ff6c5: Waiting\n",
      "405aa7f9a1db: Waiting\n",
      "86f0cc586e78: Waiting\n",
      "30b51295ff33: Waiting\n",
      "33e57ea5b30a: Waiting\n",
      "851dfeb18192: Waiting\n",
      "da5e3a75a750: Waiting\n",
      "6c3e7df31590: Waiting\n",
      "1538db58ab64: Waiting\n",
      "fb1883f1cf7b: Waiting\n",
      "88156e44280f: Pushed\n",
      "6f0bc75cafcf: Pushed\n",
      "e59fb7ef57a0: Pushed\n",
      "587d555f2c9d: Pushed\n",
      "5f70bf18a086: Pushed\n",
      "181eb05384b2: Pushed\n",
      "5cb39f79cd22: Pushed\n",
      "3657817dc3f0: Pushed\n",
      "d619dfa00c73: Pushed\n",
      "f14d86fa3017: Pushed\n",
      "8c8243578a2b: Pushed\n",
      "65411ef2fe39: Pushed\n",
      "3323ffa36a6b: Pushed\n",
      "8421b2fc221a: Pushed\n",
      "6db0e47080dc: Pushed\n",
      "21b57c16a62f: Pushed\n",
      "4dd4b78d72b9: Pushed\n",
      "1dbfef547c88: Pushed\n",
      "01e7f8ae12e2: Pushed\n",
      "400ac87f472d: Pushed\n",
      "405aa7f9a1db: Pushed\n",
      "261c3774c596: Pushed\n",
      "0c2888617ca7: Pushed\n",
      "30b51295ff33: Pushed\n",
      "12748023f7f7: Pushed\n",
      "1538db58ab64: Pushed\n",
      "da5e3a75a750: Pushed\n",
      "e35acfadf1d1: Pushed\n",
      "f344b08ff6c5: Pushed\n",
      "c8a655e8e8cd: Pushed\n",
      "86f0cc586e78: Pushed\n",
      "851dfeb18192: Pushed\n",
      "96f5d88e1c6e: Pushed\n",
      "33e57ea5b30a: Pushed\n",
      "6c3e7df31590: Pushed\n",
      "fb1883f1cf7b: Pushed\n",
      "83d1bc0501bc: Pushed\n",
      "latest: digest: sha256:f5c61b4eaeef3a6574b1f8c71e5702eafcf8d74d583fae8812c0ac127ad8b43b size: 8513\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {region}\n",
    "algorithm_name=\"sm-lorax\"  # name of your algorithm\n",
    "tag=\"latest\"\n",
    "region='us-east-1'\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "image_uri=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:${tag}\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" --region $region > /dev/null\n",
    "fi\n",
    "\n",
    "cd sagemaker_lorax/ && docker build -t ${algorithm_name}:${tag} .\n",
    "\n",
    "# Authenticate Docker to an Amazon ECR registry\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "# Tag the image\n",
    "docker tag ${algorithm_name}:${tag} ${image_uri}\n",
    "\n",
    "# Push the image to the repository\n",
    "docker push ${image_uri}\n",
    "\n",
    "# Save image name to tmp file to use when deploying endpoint\n",
    "echo $image_uri > /tmp/image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf413655-c1c2-4e84-803e-421cea835227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is will be 622343165275.dkr.ecr.us-east-1.amazonaws.com/sm-lorax:latest\n"
     ]
    }
   ],
   "source": [
    "print(f\"image is will be 622343165275.dkr.ecr.us-east-1.amazonaws.com/sm-lorax:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d38628-9317-408f-906d-e5c9ce80fbb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"download_adapter\"></a>\n",
    "## 3. Download adapter from HuggingFace Hub and push it to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6cb518-220c-491f-ae30-50f14f2b4ec6",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are going to simulate storing our adapter weights on S3, and having LoRAX load them dynamically as we invoke them. This enables most scenarios, including deployment after you’ve finetuned your own adapter and pushed it to S3, as well as securing deployments with no internet access inside your VPC, as detailed in this [blog post](https://www.philschmid.de/sagemaker-llm-vpc#2-upload-the-model-to-amazon-s3).\n",
    "\n",
    "We first download an adapter trained with Mistral Instruct v0.1 as the base model to a local directory. This particular adapter was trained on GSM8K, a grade school math dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3230c3b-7740-4727-b8a1-eda109afe077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d351821476648589fd55eef87b0eb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a590022327694dfe94b39898c13cf8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f88f8ba2a5473889914d7dda41a341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/501 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704d21d0ab4a40689dc704e25c861eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e6a7ab3b0c4a27bdd5e90d5f30ee75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bca7c42e8049ceb370225b9ddb873a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/13.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/optimized-llm-deployment-workshop/03_multi_adapter_inference/mistral-adapter'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "HF_MODEL_ID = \"vineetsharma/qlora-adapter-Mistral-7B-Instruct-v0.1-gsm8k\"\n",
    "# create model dir\n",
    "model_dir = Path('mistral-adapter')\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download model from Hugging Face into model_dir\n",
    "snapshot_download(\n",
    "    HF_MODEL_ID,\n",
    "    local_dir=str(model_dir), # download to model dir\n",
    "    local_dir_use_symlinks=False, # use no symlinks to save disk space\n",
    "    revision=\"main\", # use a specific revision, e.g. refs/pr/21\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b00f3-ca40-4b87-9456-71df3e6efe95",
   "metadata": {},
   "source": [
    "We copy this same adapter `n_adapters` times to different S3 prefixes in our SageMaker session bucket, simulating a large number of adapters we want to serve on the same endpoint and underlying GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d9a490c-a540-4e0d-8a44-a8b886bbfac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/01\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/02\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/03\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/04\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/05\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/06\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/07\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/08\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/09\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/10\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/11\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/12\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/13\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/14\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/15\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/16\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/17\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/18\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/19\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/20\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/21\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/22\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/23\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/24\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/25\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/26\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/27\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/28\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/29\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/30\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/31\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/32\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/33\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/34\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/35\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/36\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/37\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/38\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/39\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/40\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/41\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/42\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/43\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/44\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/45\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/46\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/47\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/48\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/49\n",
      "Uploaded folder to S3 with prefix: lorax/mistral-adapters/50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def upload_folder_to_s3(local_path, s3_bucket, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_path):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            s3_object_key = os.path.join(s3_prefix, os.path.relpath(local_file_path, local_path))\n",
    "            s3.upload_file(local_file_path, s3_bucket, s3_object_key)\n",
    "\n",
    "# Upload the folder n_adapters times under different prefixes\n",
    "n_adapters=50\n",
    "base_prefix = 'lorax/mistral-adapters'\n",
    "for i in range(1, n_adapters+1):\n",
    "    prefix = f'{base_prefix}/0{i}' if i < 10 else f'{base_prefix}/{i}'\n",
    "\n",
    "    upload_folder_to_s3(model_dir, sagemaker_session_bucket, prefix)\n",
    "    print(f'Uploaded folder to S3 with prefix: {prefix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ed1b2-8b7c-4e9b-bace-7ace5f78e1ca",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "## 4. Deploy SageMaker endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c24eae-766a-4ec7-8ecf-de45f1092051",
   "metadata": {},
   "source": [
    "Now we deploy a SageMaker endpoint, pointing to our SageMaker session bucket as the ADAPTER_BUCKET env variable, which enables downloading adapters from S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731f030-39ad-4dd7-854e-59d1e0c3fe0c",
   "metadata": {},
   "source": [
    "If you have any problems deploying on g5.xlarge, you can change the instance type to g5.2xlarge or g5.4xlarge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc384be-0e98-49d0-b78c-51b715a49421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is will be 622343165275.dkr.ecr.us-east-1.amazonaws.com/sm-lorax:latest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['622343165275.dkr.ecr.us-east-1.amazonaws.com/sm-lorax:latest']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "from sagemaker import Model\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "print(f\"image is will be 622343165275.dkr.ecr.us-east-1.amazonaws.com/sm-lorax:latest\")\n",
    "# Retrieve image_uri from tmp file\n",
    "image_uri = !cat /tmp/image_uri\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02925d2b-147c-4c84-af40-cc7c32fa7993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------!"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "from sagemaker import Model\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Retrieve image_uri from tmp file\n",
    "image_uri = !cat /tmp/image_uri\n",
    "# Increased health check timeout to give time for model download\n",
    "health_check_timeout = 800\n",
    "number_of_gpu = 1\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sm-lorax\")\n",
    "\n",
    "\n",
    "# Model and Endpoint configuration parameters\n",
    "env = {\n",
    "  'HF_MODEL_ID': \"mistralai/Mistral-7B-Instruct-v0.1\", # model_id from hf.co/models\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(1024),  # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096),  # Max length of the generation (including input text)\n",
    "  'ADAPTER_BUCKET': sagemaker_session_bucket,\n",
    "}\n",
    "\n",
    "lorax_model = Model(\n",
    "    image_uri=image_uri[0],\n",
    "    role=role,\n",
    "    env=env\n",
    ")\n",
    "\n",
    "lorax_predictor = lorax_model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout, \n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a74195-30a0-4379-870e-332a7aa4f33a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sm-lorax-2024-03-18-19-14-32-114'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c53c9e7a-8a1e-4b02-bc60-77f87f7aa5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can reinstantiate the Predictor object if you restart the notebook or Predictor is None\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "endpoint_name = endpoint_name\n",
    "\n",
    "lorax_predictor = Predictor(\n",
    "    endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308c12e-365c-4737-90f5-998f849beffe",
   "metadata": {},
   "source": [
    "<a id=\"compare\"></a>\n",
    "## 5. Invoke base model and adapter, compare outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ae3e2-8634-4e4d-957a-a3d81d7490e7",
   "metadata": {},
   "source": [
    "We can invoke the base Mistral model, as well as any of the adapters in our bucket! LoRAX will take care of downloading them, continuously batch requests for different adapters, and manage DRAM and RAM by loading/offloading adapters.\n",
    "\n",
    "Let’s inspect the difference between the base model’s response and the adapter’s response:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ea512-e0af-40c5-ba3e-1253eedfd011",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ I observed a weird error that I haven't debugged yet, where S3 download failed for adapters ID 1 through 5, but worked as expected for all other adapters. Something with the S3 prefix. Added 0 before adapter id if id < 10 as a workaround.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "167babae-0fb9-4a7f-aba9-fe4e266ebdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model output:\n",
      "-------------\n",
      " Let's break down the problem:\n",
      "\n",
      "1. In April, Natalia sold clips to 48 of her friends.\n",
      "2. In May, she sold half as many clips as in April, which means she sold 48/2 = 24 clips in May.\n",
      "\n",
      "Adapter output:\n",
      "-------------\n",
      " Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "In total, Natalia sold 48 + 24 = <<48+24=72>>72 clips in April and May.\n",
      "#### 72\n"
     ]
    }
   ],
   "source": [
    "prompt = '[INST] Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? [/INST]'\n",
    "\n",
    "payload_base = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 64,\n",
    "    }\n",
    "}\n",
    "\n",
    "payload_adapter = {\n",
    "\"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 64,\n",
    "        \"adapter_id\": f'{base_prefix}/01',\n",
    "        # \"adapter_id\" : adapter_uri, \n",
    "        \"adapter_source\": \"s3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response_base = lorax_predictor.predict(payload_base)\n",
    "response_adapter = lorax_predictor.predict(payload_adapter)\n",
    "\n",
    "print(f'Base model output:\\n-------------\\n {response_base[0][\"generated_text\"]}')\n",
    "print(f'Adapter output:\\n-------------\\n {response_adapter[0][\"generated_text\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1010056-9b46-4c62-880c-9f4552aa2af7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"benchmark\"></a>\n",
    "## 6. Benchmark single adapter vs. random access to adapters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67667c2d-c154-42dc-9be7-d577f8855e1d",
   "metadata": {},
   "source": [
    "First, we individually call each of the adapters in sequence, to make sure they are previously downloaded to the endpoint instance’s disk. We want to exclude S3 download latency from the benchmark metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cdeea08-31e8-411c-a57b-c4acdd702f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:39<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(1,n_adapters+1)):\n",
    "    adapter_id = f'{base_prefix}/0{i}' if i < 10 else f'{base_prefix}/{i}'\n",
    "    payload_adapter = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 64,\n",
    "        \"adapter_id\": adapter_id,\n",
    "        \"adapter_source\": \"s3\"\n",
    "        }\n",
    "    }\n",
    "    lorax_predictor.predict(payload_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eeb399-7490-4697-9871-777038232200",
   "metadata": {},
   "source": [
    "Now we are ready to benchmark. For the single adapter case, we invoke the adapter `total_requests` times from `num_threads` concurrent clients.\n",
    "\n",
    "For the multi-adapter case, we invoke a random adapter from any of the clients, until all adapters have been invoked `total_requests//num_adapters` times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520c962-f064-4e8a-a9ce-2405084e3f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust if you run into connection pool errors\n",
    "# import botocore\n",
    "\n",
    "# Configure botocore to use a larger connection pool\n",
    "# config = botocore.config.Config(max_pool_connections=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88907dd4-d805-4007-8147-84a6eebeab6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c94ddaa-4d57-4139-8e76-b87593fb155e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "# Configuration\n",
    "total_requests = 300\n",
    "num_adapters = 50\n",
    "num_threads = 20  # Adjust based on your system capabilities\n",
    "\n",
    "\n",
    "# Shared lock and counters for # invocations of each adapter \n",
    "adapter_counters = [total_requests // num_adapters] * num_adapters\n",
    "counters_lock = threading.Lock()\n",
    "\n",
    "def invoke_adapter(aggregate_latency, single_adapter=False):\n",
    "    global total_requests\n",
    "    latencies = []\n",
    "    while True:\n",
    "        with counters_lock:\n",
    "            if single_adapter:\n",
    "                adapter_id = 1\n",
    "                if total_requests > 0:\n",
    "                    total_requests -= 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                # Find an adapter that still needs to be called\n",
    "                remaining_adapters = [i for i, count in enumerate(adapter_counters) if count > 0]\n",
    "                if not remaining_adapters:\n",
    "                    break\n",
    "                adapter_id = random.choice(remaining_adapters) + 1\n",
    "                adapter_counters[adapter_id - 1] -= 1\n",
    "\n",
    "        prompt = '[INST] Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? [/INST]'\n",
    "        invoke_adapter_id = f'{base_prefix}/0{i}' if i < 10 else f'{base_prefix}/{i}'\n",
    "        payload_adapter = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 64,\n",
    "                \"adapter_id\": invoke_adapter_id,\n",
    "                \"adapter_source\": \"s3\"\n",
    "            }\n",
    "        }\n",
    "        start_time = time.time()\n",
    "        response_adapter = lorax_predictor.predict(payload_adapter)\n",
    "        latency = time.time() - start_time\n",
    "        latencies.append(latency)\n",
    "\n",
    "    aggregate_latency.extend(latencies)\n",
    "\n",
    "def benchmark_scenario(single_adapter=False, num_threads=20):\n",
    "    threads = []\n",
    "    all_latencies = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(num_threads):\n",
    "        thread_latencies = []\n",
    "        all_latencies.append(thread_latencies)\n",
    "        thread = threading.Thread(target=invoke_adapter, args=(thread_latencies, single_adapter))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    total_latency = sum([sum(latencies) for latencies in all_latencies])\n",
    "    total_requests_made = sum([len(latencies) for latencies in all_latencies])\n",
    "    if total_requests_made <=0 :\n",
    "        total_requests_made = 1\n",
    "    average_latency = total_latency / total_requests_made\n",
    "    throughput = total_requests_made / (time.time() - start_time)\n",
    "\n",
    "    print(f\"Total Time: {time.time() - start_time}s\")\n",
    "    print(f\"Average Latency: {average_latency} s\")\n",
    "    print(f\"Throughput: {throughput} requests/s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f366f0d-5118-4343-b54a-68972f5217c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking: Single Adapter Multiple Times\n",
      "Total Time: 44.282410860061646s\n",
      "Average Latency: 2.9100885208447775 s\n",
      "Throughput: 6.774699079147043 requests/s\n",
      "\n",
      "Benchmarking: Multiple Adapters with Random Access\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[134], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m benchmark_scenario(single_adapter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBenchmarking: Multiple Adapters with Random Access\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mbenchmark_scenario\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[22], line 69\u001B[0m, in \u001B[0;36mbenchmark_scenario\u001B[0;34m(single_adapter, num_threads)\u001B[0m\n\u001B[1;32m     67\u001B[0m total_latency \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([\u001B[38;5;28msum\u001B[39m(latencies) \u001B[38;5;28;01mfor\u001B[39;00m latencies \u001B[38;5;129;01min\u001B[39;00m all_latencies])\n\u001B[1;32m     68\u001B[0m total_requests_made \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([\u001B[38;5;28mlen\u001B[39m(latencies) \u001B[38;5;28;01mfor\u001B[39;00m latencies \u001B[38;5;129;01min\u001B[39;00m all_latencies])\n\u001B[0;32m---> 69\u001B[0m average_latency \u001B[38;5;241m=\u001B[39m \u001B[43mtotal_latency\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_requests_made\u001B[49m\n\u001B[1;32m     70\u001B[0m throughput \u001B[38;5;241m=\u001B[39m total_requests_made \u001B[38;5;241m/\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal Time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart_time\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Run benchmarks\n",
    "print(\"Benchmarking: Single Adapter Multiple Times\")\n",
    "benchmark_scenario(single_adapter=True)\n",
    "\n",
    "print(\"\\nBenchmarking: Multiple Adapters with Random Access\")\n",
    "benchmark_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60afe800-6dd6-4362-ba4d-b44caa8c8023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking: Multiple Adapters with Random Access\n",
      "Total Time: 43.7987117767334s\n",
      "Average Latency: 2.8808842070897422 s\n",
      "Throughput: 6.849516821263714 requests/s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBenchmarking: Multiple Adapters with Random Access\")\n",
    "benchmark_scenario()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde0454-3e6b-4c63-b7b6-d5e8095a863d",
   "metadata": {},
   "source": [
    "### Bench mark thread pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2dfd4d44-d1af-497d-a770-8f3b5ca3c9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import serializers, deserializers\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import jinja2\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# variables\n",
    "s3_client = boto3.client(\"s3\")\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "model_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "\n",
    "jinja_env =  jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "\n",
    "\n",
    "\n",
    "def run_worker_endpoint(worker_id, adaptor_id):\n",
    "\n",
    "    # make a inference request to load model into memory\n",
    "    runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "    print(f\"Starting invocation for model:: worker_id={worker_id}:::  adaptor_id={adaptor_id}::....please wait ...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = [0]\n",
    "    total_count=0\n",
    "    error_count=0\n",
    "    #base_prefix = 'lorax/mistral-adapters'\n",
    "    total_run_time = 40 #10  #120: #3600: #400:  # -- 300 sec  -- 1 hour 3600    2 hour 7200 is 4 is 14400\n",
    "    \n",
    "    while (time.time() - start_time) < total_run_time: #120: #3600: #400:  # -- 300 sec  -- 1 hour 3600    2 hour 7200 is 4 is 14400\n",
    "        start_run = time.time()\n",
    "        try:\n",
    "            prompt = '[INST] Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? [/INST]'\n",
    "            invoke_adapter_id = f'{base_prefix}/0{adaptor_id}' if adaptor_id < 10 else f'{base_prefix}/{adaptor_id}'\n",
    "            payload_adapter = {\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": {\n",
    "                    \"max_new_tokens\": 64,\n",
    "                    \"adapter_id\": invoke_adapter_id,\n",
    "                    \"adapter_source\": \"s3\"\n",
    "                }\n",
    "            }\n",
    "            response = runtime_sm_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"application/json\",\n",
    "                Body=json.dumps(payload_adapter),\n",
    "            )\n",
    "            results.append((time.time() - start_run) * 1000)\n",
    "            total_count = total_count + 1\n",
    "\n",
    "        except:\n",
    "            print(traceback.format_exc())\n",
    "            error_count = error_count + 1\n",
    "            time.sleep(0.005)\n",
    "     \n",
    "    if total_count <=0 :\n",
    "        total_count = 1\n",
    "    print(f\"worker_id={worker_id}::adaptor_id={adaptor_id}:: p95::{np.percentile(results, 95)} ms:throughput={total_run_time/total_count}::total_success_count={total_count}::error_count={error_count}::\")\n",
    "\n",
    "    return (np.percentile(results, 90), (total_count/total_run_time)*60, total_count, error_count) # - latency, throughput in TPM, total run , error count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "041d42c0-04b4-473c-beb9-6281cb5d629f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_A-Sync:processes=40\n"
     ]
    }
   ],
   "source": [
    "# create a process pool\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "max_workers_cpu = 40 #3 #4 #5  # cpu_count() # -*2\n",
    "print(f\"Max_A-Sync:processes={max_workers_cpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1326139-cb91-49da-aa6d-39068badc6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_adaptors_to_run = 1 #40\n",
    "max_adaptors = 50\n",
    "remaining_adaptors = [i+1 for i in range(max_adaptors)] # - adaptors id is 1 base\n",
    "#remaining_adaptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2e4c6105-2c3e-40f6-bc2f-a16516c9bd12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "<Future at 0x7f16be573af0 state=running>\n",
      "Starting invocation for model:: worker_id=0:::  adaptor_id=46::....please wait ...\n",
      "worker_id=0::adaptor_id=46:: p95::2416.24196767807 ms:throughput=2.3529411764705883::total_success_count=17::error_count=0::\n"
     ]
    }
   ],
   "source": [
    "result_pool_list = []\n",
    "print(max_workers_cpu)\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers_cpu) as pool:\n",
    "    # call a function\n",
    "\n",
    "    for worker in range(max_adaptors_to_run): # run certain adaptors\n",
    "        adaptor_id = random.choice(remaining_adaptors) \n",
    "        result_p = pool.submit(run_worker_endpoint, worker,adaptor_id ) # -- making worker id 1 based to test 20 models in 1 instance\n",
    "        print(result_p)\n",
    "        result_pool_list.append(result_p)\n",
    "        \n",
    "        remaining_adaptors.remove(adaptor_id) # so a new adaptor get assigned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "559dd427-b47a-4d9f-9967-aeb9ccb3b46a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2414.013719558716, 25.5, 17, 0)\n"
     ]
    }
   ],
   "source": [
    "for result_p in result_pool_list:\n",
    "    print(result_p.result()) # blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a1b33d2b-f4ef-4cbc-bf0a-29216af3718b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_adaptors_to_run=1::P90 Average:latency--->2414.013719558716:ms: and P90 throughput --- >25.5:TPM:   total_count=17\n"
     ]
    }
   ],
   "source": [
    "time_in_ms_list = []\n",
    "throughput_run_list = []\n",
    "total_run = 0\n",
    "\n",
    "for result_p in result_pool_list:\n",
    "    time_in_ms, throughput_run , total_count, error_count = result_p.result()\n",
    "    time_in_ms_list.append(time_in_ms)\n",
    "    total_run = total_run + total_count\n",
    "    throughput_run_list.append(throughput_run)\n",
    "    \n",
    "p90_avg = np.percentile(time_in_ms_list, 90)\n",
    "p90_throughput = np.percentile(throughput_run_list, 90)\n",
    "\n",
    "print(f\"max_adaptors_to_run={max_adaptors_to_run}::P90 Average:latency--->{p90_avg}:ms: and P90 throughput --- >{p90_throughput}:TPM:   total_count={total_count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "07d371c9-8bf4-4e00-8424-6cfd933359ff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "max_adaptors_to_run=1::P90 Average:latency--->2406.642436981201:ms: and P90 throughput --- >30.0:TPM:   total_count=5\n",
    "\n",
    "max_adaptors_to_run=5::P90 Average:latency--->3363.8840293884277:ms: and P90 throughput --- >24.0:TPM:   total_count=4\n",
    "\n",
    "max_adaptors_to_run=10::P90 Average:latency--->3877.0756030082703:ms: and P90 throughput --- >24.0:TPM:   total_count=3\n",
    "\n",
    "max_adaptors_to_run=15::P90 Average:latency--->4221.390309333801:ms: and P90 throughput --- >24.0:TPM:   total_count=3\n",
    "\n",
    "max_adaptors_to_run=20::P90 Average:latency--->4366.228897571564:ms: and P90 throughput --- >24.0:TPM:   total_count=3\n",
    "\n",
    "max_adaptors_to_run=30::P90 Average:latency--->4437.815496921539:ms: and P90 throughput --- >18.0:TPM:   total_count=3\n",
    "\n",
    "max_adaptors_to_run=40::P90 Average:latency--->4845.03347158432:ms: and P90 throughput --- >18.0:TPM:   total_count=3\n",
    "\n",
    "Benchmarking: Single Adapter Multiple Times\n",
    "Total Time: 44.282410860061646s\n",
    "Average Latency: 2.9100885208447775 s\n",
    "Throughput: 6.774699079147043 requests/s\n",
    "\n",
    "max_adaptors_to_run=1::P90 Average:latency--->2414.013719558716:ms: and P90 throughput --- >25.5:TPM:   total_count=17\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee9521-f5ed-487b-ba84-5a834add3d78",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "## 7. Cleanup endpoint resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af920da7-c0ce-4f3f-9eea-297abb49b342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lorax_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
